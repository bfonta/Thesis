* The problem




+ QCD simulations lack of precision and statistics for a robust bkg estimate, therefore a data-driven background modeling is needed
+ The QCD multijet background completely dominates the 4b final state (>90%), but is challenging to model with simulation: it is not computationally feasible to generate large enough samples with enough precision in all corners of the phase-space
  + the remaning background is mostly $t\bar{t}$
+ The development of a high-dimensional data-driven background model is thus necessary
+ The ZZ and ZH processes represent standard candles to validate the HH analyses, given that they have larger cross-sections, 31 and 8 times larger than HH, respectively.
+ Data-driven background models are often derived using the so-called "ABCD" method (just like for the $bb\tau\tau$ analysis). The background is derived in a signal-free region, and thus requires an extrapolation to a different region of the phase-space. In order to validate the extrapolation, a validation region is usually employed. However, the definition of an additional region will necessarily deplete the signal region. Additionally, we cannot directly test the extrapolation, since the validation region will differ from the signal region inasmuch as it will not be signal-enriched. New methods to validate the background are thus welcome.

#+NAME: fig:hcr_architecture
#+ATTR_LATEX: :width .9\textwidth
#+CAPTION: Branching fractions for the decay of a HH pair to a selected group of final states indicated on the top and left sides. The three decay channels currently showcasing the highest sensitivity ("silver bullets") are indicated in dashed gray. No single channel dominates the sensitivity of di-Higgs combinations. The four coloured markers represent the \ac{CMS} published analysis so far. Additional decay channels are currently being explored, together with ttHH production.
[[~/org/PhD/Thesis/figures/HH_production_diagram.pdf]]

* Hierarchical combinatoric residual network (HCR)
+ Used as classifier for the $ZH/ZZ\rightarrow bbbb$ analysis
+ Used to define the background model
+ Used to remove the ttbar background from the synthetic datasets (see "Improvement #2" below)

# #+NAME: fig:hcr_architecture
# #+ATTR_LATEX: :width 1.\textwidth
# #+CAPTION: HCR architecture.
# [[~/org/PhD/Thesis/figures/HCR_architecture.pdf]]

The architecture comprises a series of convolutions and residual connections

* Modelling the QCD background
+ The background model is defined using a sample with similar selections as in the analysis' signal region, but dropping one of the b-tag requirements on one of the four b-jet candidates.
+ Statistics are increased by lowering the b-tag WP used on the three jets
+ The analysis four-jet background is modelled by weighting the three-jet background with two sets of weights:
  1. jet combinatorial model: account for additional jet activity. The parameters of the model (Eq. 4 in HIG-22-011) are determined by a combined fit to the jet and b-tagged het multiplicity distributions in the sidebands
  2. kinematic weighting: correct kinematic differences
+ The weights are derived in a di-jet mass sideband
  
* Hemisphere Mixing
+ The existence of synthetic datasets enables to fully validate the extrapolation to a signal-enriched region, and enables to estimate the variance of the background prediction coming from the finite dataset size
+ The method first creates a library of hemispheres, by dividing jets in four-b-tagged based on a plane orthogonal to the transverse thrust axis: jets on either side are assigned to one of the two hemispheres
  + The thrust axis is defined as the axis on which the sum of the absolute values of the projections of the pT of the jets is maximal
+ A set of variables is calculated for each hemisphere: mass, longitudinal momentum and transverse momentums perpendicular and parallel to the thrust axis
+ A second pass on data assigns a pair to each hemisphere by minimizing the distance of two hemisphere in terms of a normalized sum of the hemisphere summary variables
+ A check ensures the two hemispheres belong to different events
+ The nearest-neighbour hemispheres are rotated in $\phi$ to match the direction of the tranvserse thrust axis of the input event
+ *Improvement 1*: consider the 3-tagged dataset for the second pass (instead of the 4-tagged dataset), ensuring more statistics and avoid a possible bias caused by the presence of signal events when considering the 4-tagged dataset
+ *Improvement 2*: avoid mixing $t\bar{t}$ hemispheres with QCD hemispheres: use the HCR architecture to calculate the probability P(M) for an event to be multijet. This is done event-by-event. FOr each event, a random number X is generated between 0 and 1. If X > P(M) the event is rejected.
+ For the validation of the background model, we have to ensure the size of the synthetic dataset is comparable to the one used for the model. The hemisphere dataset is then sub-samples, and 15 separate mixed models are created, given the available statistics.
+ *Systematics:* The 15 models are all used to derive the systematic uncertainties of the background modelling in three steps:
  1. Differences between each mixed model, arising from limited statistics, are quantified by using their average
  2. Compare background model with mixed models in the signal region
  3. Check if a spurious signal can be mimicked by the background model, by adding an unconstrained signal template to the fit and comparing it with the background-only fit. The two are found to be in agreement, and no significant improvement of the model fit is observed.

* Final fit
+ The final fit is validated using the synthetic datasets, without statistical fluctuations, and using one of the mixed models as the four-tag data. Systematics behaved as expected and the result was compatible with a zero signal strength

* Projections
+ Four projection scenarios are considered for the evolution of background uncertainties
  + constant background uncertainties
  + scaling variance terms by $1/\sqrt{\mathcal{L}}$ while keeping the extrapolation uncertainty constant
  + naive $1/\sqrt{\mathcal{L}}$ scaling of the limits
  + no background systematics

* Additional bibliography :noexport:
** 4b novel techniques
+ [[https://cms.cern.ch/iCMS/analysisadmin/cadilines?line=HIG-20-005&tp=an&id=2316&ancode=HIG-20-005][HIG-20-005]] (4b resolved)
+ [[https://cms.cern.ch/iCMS/analysisadmin/cadilines?line=HIG-22-011&tp=an&id=2605&ancode=HIG-22-011][HIG-22-011]] (ZZ/ZH->4b)
  + [[https://indico.cern.ch/event/1275872/][DeepDive QCD modelling]]
