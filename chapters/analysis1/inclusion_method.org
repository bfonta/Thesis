:PROPERTIES:
:CUSTOM_ID: sec:inclusion_method
:END:

The probability that at least one out of $N_{\text{items}}$ trigger items $i$ accepts an event $j$ with trigger item bit $x$ is given by [[cite:&inclusion_method]]:

#+NAME: eq:prob_or
\begin{equation}
  P_{j} = 1 - \prod^{N_{\text{items}}}_{i=1} \left[ 1 - x_{ij}\epsilon_{i}(q_{j})\right]
\end{equation}

\noindent where $\epsilon$ refers to the trigger efficiency (depending on variables $q$), defined as the number of events passing trigger item $i$ and some reference trigger, divided by the number of events passing the same reference trigger.
In [[eq:prob_or]], we use the fact that the triggers we consider are not prescaled and different data runs have the same conditions.
Correlations might exist between triggers, so we rewrite $x_{1j}\epsilon_{1j}x_{2j}\epsilon_{2j} \rightarrow x_{1j}\epsilon_{1j}x_{2j}\epsilon_{2|1j}$ 
(note the commutativity $\epsilon_{1j}\epsilon_{2|1j} = \epsilon_{2j}\epsilon_{1|2j}$), where $\epsilon_{i}(q_{j}) \equiv \epsilon_{ij}$ simplifies the notation.
Using Bayes' theorem we express the efficiency product as an \textit{intersection efficiency} $\epsilon_{1\cap2j}$, representing the fraction of events passing triggers 1 and 2, plus some reference trigger, relative to all events that pass the same reference trigger.
The probability becomes:

#+NAME: eq:example3
\begin{align}
  P_{j} &= x_{1j}\epsilon_{1j} + x_{2j}\epsilon_{2j} + x_{3j}\epsilon_{3j} + \cdots \nonumber \\
        &- x_{1j}x_{2j}\epsilon_{1\cap2j} - x_{1j}x_{3j}\epsilon_{1\cap3j} - x_{2j}x_{3j}\epsilon_{2\cap3j} - \cdots \nonumber \\
        &+ x_{1j}x_{2j}x_{3j}\epsilon_{1\cap2\cap3j} + \cdots
\end{align}

\noindent For each intersection, we must define variable(s) $q$.
We should consider the ones used in the definition of trigger items, since correlations are large.
Finally, we can correct our MC distributions event-by-event, using the \acp{SF}:

#+NAME: eq:inclusion_sf
\begin{equation}
  \text{Event}_{\text{MC, Corrected}} =   \text{Event}_{\text{MC}} \times \frac{P_{\text{Data}}}{P_{\text{MC}}}
\end{equation}

\noindent This is called the \textit{inclusion method}, and its implementation is challenging. 
Many intersections might have to be considered.
Their calculation is done as a function of different variables $q$ (potentially 1D, 2D or 3D $\epsilon$ distributions), for all intersections.
We nevertheless note that the terms of \cref{eq:prob_or} with more triggers will naturally be the ones that contain less events overall, and can be dropped when statistics lie below a tunable threshold.
Importantly, orthogonal reference triggers have to be found for each intersection, where the latter should have enough statistics.
Finally, the method represents a new approach, thus requiring extensive testing.

However, it also brings important advantages.
Contrary to common division-like methods, all data are used.
It may become very advantageous when significant overlap exists between triggers. 
Indeed, most analysis do not consider the \logicor{} between triggers due to the increased complexity.
I developed an analysis-independent framework to measure all intersection efficiencies, using workflow management techniques for automation.
A preliminary test was carried using the \mutau{} channel to exploit its large statistics.
For simplicity, we used the muon \ac{pt} as $q$ across all intersections.
We consider the \logicor{} between the \stau{} and \mutau{} triggers, and apply the standard analysis selection.
We observe that the \acp{SF} calculated via [[eq:prob_or]] provide better Data/MC agreement in the analysis phase-space than the \acp{SF} provided centrally by \ac{CMS}.
The improvement is observed only for the variable being used, namely the lepton \ac{pt}.
This encouraging result can be explained since our custom \acp{SF} are calculated with kinematics specific to \hhbbtt{}, while central \acp{SF} must be general enough to be used by multiple analysis.
Variables not correlated with the used \ac{pt} are not affected.


+ explain why the full OR was not pursued
+ say that the framework was nevertheless used to estimate $\metnomu$ \acp{SF}
+ express wish that framework is used in the future, mention \run{3}
