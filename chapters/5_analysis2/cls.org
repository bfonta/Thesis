:PROPERTIES:
:CUSTOM_ID: sec:cls
:END:

We can now use the Neyman-Pearson lemma introduced in [[#sec:lemma]] to rewrite the optimal test statistic using the likelihood function.
To test a given value of the signal strenght modifier $\mu$, we define the /\ac{PRL}/ [[cite:&asimov]]:

#+NAME: eq:PRL
\begin{equation}
\lambda(\mu) \equiv \frac{\mathcal{L}(\mu,\hat{\theta}_{\mu})}{\mathcal{L}(\hat{\mu},\hat{\theta})} \: ,
\end{equation}

\noindent where $\hat{\mu}$ and $\hat{\theta}$ in the denominator are the maximum likelihood estimators of $\mu$ and $\theta$, respectively, and $\hat{\theta}_{\mu}$ denotes the value of $\theta$ that maximizes the likelihood for a given $\mu$.
In other words, the denominator is the unconditional maximized likelihood function, obtained when the minimization is performed simultaneously on $\mu$ and $\theta$, while the numerator is conditioned on the value of $\mu$ being probed.
$\lambda(\mu)$ is by construction bounded between 0 and 1, and higher values correspond to better compatibilities between the data and $\mu$.

The nuisance parameters introduced in [[eq:log_normal]] make the profile likelihood broader, reflecting the information lost due to systematic uncertainties.
Negative values for $\hat{\mu}$ are permitted, as long as the bin counts $\mu\,s_i + b_i$ remain non-negative.
Such a choice allows the extraction of asymptotic properties from $\lambda(\mu)$ such that it can be derived with analytical formulas, as will be described in [[#sec:exp_vs_obs]].

* Excesses
In order to quantify an excess, the following test statistic is defined:

#+NAME: eq:excess_quantify
\begin{equation}
q_0 \equiv \left\{
        \begin{array}{ll}
        -2\ln{\lambda(0)} & \mbox{if } \hat{\mu}\geq0 \\
                0 & \mbox{if } \hat{\mu}<0
        \end{array}
      \right. \:\:\: .
\end{equation}

\noindent The level of agreement between the data and the hypothesized $\mu$ value can be expressed by the /p-value/.
The p-value represents the probability, under the assumption of the null hypothesis, of obtaining a result equal or more extreme (less compatible) than the one obtained with the measured value of the test statistic, $q_{0}^{\text{obs.}}$ for excesses.
The formal definition is given by:
#+NAME: eq:pvalue_limit
\begin{equation}
p = \int_{q_{0}^{\text{obs.}}}^{\infty} f(q_{0} | \mu=0) \, dq_{0} \: ,
\end{equation}

\noindent which can be converted into a significance Z, using a one-side Gaussian integral, often used to report results in \ac{HEP} publications:
#+NAME: eq:significance
\begin{equation}
  p = \int_{\text{Z}}^{+\infty} \frac{1}{\sqrt{2\pi}}e^{-x^2/2}dx \: .
\end{equation}

\noindent Two levels of significance are traditionally defined.
An /evidence/ corresponds to $\text{Z}=3$, or equivalently $p=1.3\times10^{-3}$, and an /observation/ sets the bar higher at $\text{Z}=5$, or $p=2.8\times10^{-7}$.

When looking for resonances as a function of multiple hypothesis, as done for \xhhbbtt{} in terms of the resonance masses $\mx$, the p-value in [[eq:pvalue_limit]] underestimates the chances of observing fluctuations when jointly considering all signals being probed.
In other words, the /local/ significance, as computed for a fixed value of a measured parameter, systematically overestimates the more correct, /global/ significance, in a phenomenon dubbed the /look-elsewhere effect/.
This effect takes place because $q$ will depend on several hypotheses $m$, $q(m)$, and not just on a single $m_k$, and thus one has to take into account background fluctuations at any hypothesis value in the relevant domain.
The local p-value is thus converted into a global one by using a new test statistic, computed by taking the maximum value of test statistics over the hypothese's domain [[cite:&stat_procedure_comb_higgs]]:
#+NAME: eq:globa_pvalue
\begin{equation}
q(\mu) = \max_{i} q(\mu; m_i) \: .
\end{equation}

\noindent We remark that the effect will become stronger for worse detector resolutions, since it become more likely to observe many shifts in the reconstructed masses, thus mimicking an excess over the background [[cite:&lista]].

* Upper limits
When setting upper limits on the strength parameter $\mu$, the following test statistic $q_{\mu}$ is defined, being a generalization of [[eq:excess_quantify]]:
#+NAME: eq:upper_limits
\begin{equation}
q_{\mu} \equiv \left\{
	\begin{array}{ll}
	  -2\ln{\lambda(\mu)} & \mbox{if } \hat{\mu}\leq\mu \\
	  0 & \mbox{if } \hat{\mu}>\mu
	\end{array}
\right. \: .
\end{equation}

\noindent Due to the negative sign, larger values of $q_{\mu}$ indicate that the probability for observing the data given $\mu$ is smaller, \ie{} the data and parameters become increasingly incompatible.
The test statistic is set to zero for $\hat{\mu}>\mu$ because, in the specific case of an upper limit, such a situation would not be interpreted as a rejection of the null hypothesis, as we would be probing a value of $\mu$ that lies closer to the background-only hypothesis than the maximum likelihood estimator $\hat{\mu}$.

The test statistic in [[eq:upper_limits]] can be exploited to define exclusion limits via the modified frequentist confidence level criterion [[cite:&cls1;&cls2]].
Given $q_{\mu}^{\text{obs.}}$, we calculate the probabilities for $q_{\mu}$ to be equal or larger under the null or alternative hypotheses:
#+NAME: eq:pvalue_like
\begin{align}
  p_{s+b} &= P(q_{\mu} \geq q_{\mu}^{\text{obs.}} | \, s + b) = \int_{q_{\mu}^{\text{obs.}}}^{\infty} f(q_{\mu} | \, s+b) \, dq_{\mu} \nonumber \\
  p_{b} &= P(q_{\mu} \geq q_{\mu}^{\text{obs.}} | \, b) = \int_{q_{\mu}^{\text{obs.}}}^{\infty} f(q_{\mu} | \, b) \, dq_{\mu}
\end{align}

\noindent A given signal strength $\mu$ is said to be excluded at a confidence level $\text{CL} = 1 - \alpha$ if one finds:
#+NAME: eq:cls
\begin{equation}
    \text{CL}_{\text{s}}(\mu) \equiv \frac{p_{s+b}}{p_b} < \alpha
\end{equation}

\noindent where $\alpha$ is the significance level introduced in [[eq:significance_level]].
The inclusion of the denominator protects against cases where $s \ll b$, where signal models can be excluded when there is no sensitivity due to underfluctuations of the background.
A value of 5% is commonly chosen for the significance level, leading to the 95% \ac{CL} results quoted in [[#sec:final_limits]].
The limits are obtained on the \ac{POI} $\mu$, but are rescaled to the cross section of the signal process.

* Extra :ignore:
+ discuss the flip-flop, or when to quote a measurement or a limit
