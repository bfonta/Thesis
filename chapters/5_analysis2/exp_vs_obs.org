:PROPERTIES:
:CUSTOM_ID: sec:exp_vs_obs
:END:

The statistical treatment so far described is centered around the usage of a (hopefully discriminant) test statistic, ultimately defining how sensitivity analyses become.
A potentially minor adjustement in the analysis' selection, or a slight change in the training of the final discriminant, for instance, might very well modify the test statistic, and thus affect the final limits.
What would then happen after producing limits over and over again, each time iterating on the analysis strategy and obtaining better performances?
The final result would become biased, since decisions would be made given the final results, potentially leading to the appearance of spurious excesses, like the $\gamma\gamma$ bump seen in 2015 at \SI{750}{\GeV}.
Instead, \ac{HEP} analyses start /blinded/: the data in the \ac{SR} is not looked at until the analysis strategy is considered stable.
Data in \acp{CR} can be used, together with all \ac{MC} samples.

During the blinded stage, the analysis' sensitivity is assessed via /expected results/.
However, computing the median significance of a dataset is a computationally-intensive task, requiring the generation of large quantities of pseudo-data.
A different approach is possible, by exploiting the asymptotic limit of the \ac{PRL}.

+ introduce Wilk's theorem: when a large dataset is available, assuming some regularity conditions on the likelihood, any test statistic based on the \ac{PRL} can be approximated by a $\chi^{2}$ distribution with $k$ degrees of freedom, being $k$ given by the number of \acp{POI} [[cite:&Wilks:1938dza]]
  
Such properties enable the definition of the Asimov dataset [[cite:&asimov]], a representative dataset where all observed quantities (\ac{POI} and nuisances) are set to their expected values, and statistical fluctuations are not considered.

Once all possible issues in the analysis have been addressed and understood, the /unblinding/ step can proceed, in which the maximum likelihood fit provides the /observed/ result.



