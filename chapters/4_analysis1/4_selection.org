:PROPERTIES:
:CUSTOM_ID: sec:selection
:END:

The observation of \xhhbbtt{} naturally requires the capability to precisely reconstruct the two pairs of b jets and tau leptons.
Having introduced all single physics objects included in the \bbtt{} topology, we can now describe in detail the full event selection, which aims at providing the subset of events processed that match the signal of interest.
However, the selection should not be too strict, or equivalently lead to a very high \bbtt{} purity; that could hinder analysis steps to come, and specifically affect the final discriminator, by reducing its training data size.
Given the rarity of HH processes, it is imperative to measure as many \hhbbtt{} events as possible; the goal of the selection is to maximize signal acceptance.

The selection starts from the data passing the analysis triggers, and is performed in various stages, as also highlighted in [[fig:analysis_flow]].
The stages proceed in order, by targeting single objects first, such as b jets, leptons and \tauhs{}, and later pairs of such quantities, as defined by the decays of the two Higgs bosons.
Once the two H candidates have been found, an additional two-dimensional invariant mass cut is applied on the $\mbb$ and $\mtautau$ plane, to further restrict the phase-space of interest, removing potential outliers, and to provide validation \acp{CR}.
A categorization step immediately follows, where /categories/ are defined.
This step separates events according to the topology of the b-quark pair, creating two resolved and one boosted category.
The categories are created in order to boost the sensitivity of a dedicated /discriminant variable/, which is described in the next Chapter.

In the following, we detail the selection cuts applied to leptons and b jets in [[ref:sec:tau_pair_sel,sec:b_pair_sel]].
All events that satisfy the selection on tau leptons and b-quark pairs are said to belong to the \basecat{} selection.
We then proceed by introducing the invariant mass cut in [[#sec:mass_cut]] and the categorization step in [[#sec:categorization]].
Finally, we provide the definitions of the two \acp{CR} used in the analysis, which are used to train the discriminant and are visualized in [[#sec:control_regions]].

* Tau Lepton Pair
:PROPERTIES:
:CUSTOM_ID: sec:tau_pair_sel
:END:

This step aims at identifying the visible decay products of one of the \SI{125}{\GeV} Higgs bosons decaying to a $\tau$ pair.
Selected signal events are required to have at least one $\tau$ candidate decaying hadronically and that has been reconstructed by the \ac{HPS} algorithm.  
The =DeepTau= discriminator [[cite:&deeptau]] identifies \tauhs{}, distinguishing them from jets, electrons and muons.
Due to charge conservation, \ac{HPS} decay modes with two prongs are explicitly rejected.
Furthermore, all events assigned the $\text{h}^{\pm}\pi^{0}\pi^{0}\nu_{\tau}$ topology are analyzed as though they were $\text{h}^{\pm}\pi^{0}\nu_{\tau}$.
This happens because the former is much rarer than the latter, and the \ac{HPS} algorithm is not tuned to reconstruct decays containing two $\pi^0\text{s}$.
This same assignment is also taken into account when applying =DeepTau= \acp{SF}, as described in [[#sec:deep_tau_sfs]]
The identification requirement applied to \tauhs{} is the =Medium= \ac{WP} of the =DeepTauVSjet= algorithm, the =Tight= =DeepTauVSmu= \ac{WP}, and the =VVLoose= =DeepTauVSe= discriminator.
Their efficiencies are listed in [[tab:deeptau_wps]].
The choice of \acp{WP} is related to the \acp{WP} used by the Tau \ac{POG} to derive \acp{SF} for genuine \tauhs{}, which have a dependency on =DeepTauVSmu= and =DeepTauVSe=.
The reasoning is to use corrections as close to POG recommendations as possible, in order to reach a good data/MC agreement in all relevant parts of the parameter space.

#+NAME: tab:max_min_cuts
#+CAPTION: List of the minimum $\pt$ and maximum $|\eta|$ thresholds considered for electron, muon and tau lepton candidates. These value are a consequence of hard limits imposed by object-specific \acp{SF},as provided by the relevant \acp{POG}. Leptons firing triggers with tighter \ac{pt} cuts must apply the thresholds according to [[eq:ptTreshold]].
#+ATTR_LATEX: :placement [!h] :center t :align lcc :environment mytablewiderrows
|------------+--------------------------+-------------|
| *Object*     | $\pmb{\pt\,[\si{\GeV}]}$ | $\pmb{\vert\eta\vert}$ |
|------------+--------------------------+-------------|
| Electron   | $>10$                    | $<2.5$      |
| Muon       | $>15$                    | $<2.4$      |
| Tau lepton | $>20$                    | $<2.3$      |
|------------+--------------------------+-------------|

All events lying above the minimum $\pt$ or below the maximum $|\eta|$ values reported in [[tab:max_min_cuts]] are considered, as long as they satisfy the triggers described in [[#sec:triggers]], and as long as the offline objects are geometrically matched to the online \ac{HLT} paths.
The values in [[tab:max_min_cuts]] come from hard limits imposed by the isolation and \ac{ID} trigger \acp{SF} used in the analysis.
We look for lepton candidates passing simple kinematic, isolation and \ac{ID} criteria, as summarized in [[tab:chn_sel]], where the $\Delta_{xy}$ and $\Delta_{z}$ distances are also taken into account, measuring the compatibility with the \ac{PV}.
Additionally, the two objects in a pair should have opposite charges, and should pass \ac{pt} thresholds based on the triggers they fired.
An exception occurs for the $\metnomu$ trigger, since it imposes no \ac{pt} cut, and can thus explore the full phase-space presented in [[tab:max_min_cuts]].
The \ac{pt} thresholds depend on the \ac{HLT} trigger path fired by the event:
#+NAME: eq:ptTreshold
\begin{equation}
  \pt^{\text{offline}} \, \geq \, \pt^{\text{HLT}}\ + \, \text{threshold}\:,
\end{equation}
\noindent where $\pt^{\text{offline}}$ is the transverse momentum of the offline selected lepton, $\pt^{\text{HLT}}$ is the \ac{pt} threshold applied at \ac{HLT} level, and ``threshold'' depends on the lepton type: \SI{1}{\GeV} for electrons, \SI{2}{\GeV} for muons, \SI{5}{\GeV} for tau leptons firing the \ditau{} trigger, and \SI{10}{\GeV} for tau leptons firing the \stau{} trigger.
The thresholds are chosen to be conservative with respect to the trigger turn-on curves.
For events passing more than one trigger, the loosest thresholds among those two triggers are applied.

The analysis channels are defined according to specific priority rules.
An event is classified as \mutau{} if a single muon candidate passes all criteria.
If two muons pass the criteria, the event becomes \mumu{}.
In case no muon is selected, we check whether any electron passing the criteria was found.
In case a single electron candidate is present, the event is associated the \eletau{} channel.
If two electrons are present, the event would be assigned the \eleele{} channel, but it is instead discarded, as we are not taking this channel into consideration.
If neither muons or electrons are found, the event is classified as \tautau{}, as long as a two \tauhs{} are present, and all pair candidates are kept.
Within each pair, leptons are ordered as follows, depending on the channel:
+ $\pmb{\tau_{e}\tau_{\text{h}}}$ *and* $\pmb{\tau_{\mu}\tau_{\text{h}}}$:
  The first position is assigned to the leptonic leg, either a muon or an electron.
+ $\pmb{\tau_{\text{h}}\tau_{\text{h}}}$:
  All selected pairs are first sorted according to the =DeepTau= score of the first lepton.
  If the two first legs have the same isolation, the highest \ac{pt} leg is used to order the pairs.
  If the \ac{pt} is also identical, \ie{} the pairs share the same first leg, then the pair with the most isolated second leg is preferred.
  If ambiguity is still present, priority is given to the pair with the highest \ac{pt} of the second leg.
\noindent This channel classification strategy was chosen because it was seen to maximize event purity, while removing event overlaps among the three different final states.

Some events can include multiple leptons of the same kind, and their choice becomes a matter of some ambiguity.
We mentioned above that \mutau{} events take precedence over \eletau{} events; no ambiguity is present at the decay channel level.
However, nothing forbids an event to include, on top of a \tauh{}, two muons or two electrons, as long as they satisfy the requirements in [[tab:chn_sel]].
For those cases, there would be multiple ways to choose the "correct" lepton, \ie{} the lepton truly associated to the Higgs boson decay.
To simplify the selection and avoid taking the wrong decision, the /third lepton veto/ is implemented, were events with a third lepton are rejected.
This veto also helps removing background events with two leptons and a fake \tauh{}, as for instance diboson processes, or fully leptonic decays of $\ttbar{}$.
The third lepton selection criteria are very similar to the ones for the "standard" leptons, just slightly looser, in order to remove most situations where ambiguity might be present.

#+NAME: tab:chn_sel
#+CAPTION: Selections defining the analysis channels, including the third lepton vetos. Besides the cuts listed in the table, opposite charges are requested between any two leptons, and the \ac{pt} thresholds follow [[eq:ptTreshold]], except when the the leptons fired only \ac{MET}, in which case no specific cuts are requested, and [[tab:max_min_cuts]] is instead considered. The $|\eta|$ cut on the second lepton in \eletau{} and \mutau{} can be 2.1 if the event only fires the cross trigger. With the exception of not applying a $\Delta_{xy}$ cut on \tauhs{}, the $\Delta_{xy}$ and $\Delta_{z}$ cuts below are identical for any two objects in a pair, are are provided in \si{\mm}. The isolation cuts marked with $\dagger$ are applied to the isolation considering all \ac{PF} muon candidates, but also to an isolation considering only muon tracks.
#+ATTR_LATEX: :placement [!h] :center t :align lccccccccc :environment mytablewiderrows
|---------------------------+---------------+---------------------+----------------------+---------------+---------------------+----------------------+----------------+---------------+----------------------------|
| *Chn.*                      | $\pmb{\vert\eta_1\vert}$ | $\pmb{\text{ID}_1}$ | $\pmb{\text{Iso}_1}$ | $\pmb{\vert\eta_2\vert}$ | $\pmb{\text{ID}_2}$ | $\pmb{\text{Iso}_2}$ | $\pmb{\Delta_{xy}}$ | $\pmb{\Delta_{z}}$ | $\pmb{\Delta\text{R}(\ell_1,\ell_2)}$ |
|---------------------------+---------------+---------------------+----------------------+---------------+---------------------+----------------------+----------------+---------------+----------------------------|
| \eletau{}                 | $<2.5$        | \texttt{Tight}      | $<0.1$               | $<2.3$        | \texttt{DeepTau}    | \texttt{DeepTau}     | $<0.45$        | $<2.0$        | $>0.4$                     |
| \mutau{}                  | $<2.4$        | \texttt{Tight}      | $<0.15^{\dagger}$          | $<2.3$        | \texttt{DeepTau}    | \texttt{DeepTau}     | $<0.45$        | $<2.0$        | $>0.4$                     |
| \tautau{}                 | $<2.3$        | \texttt{DeepTau}    | \texttt{DeepTau}     | $<2.3$        | \texttt{DeepTau}    | \texttt{DeepTau}     | --             | $<2.0$        | $>0.4$                     |
| \mumu{}                   | $<2.4$        | \texttt{Tight}      | $<0.15^{\dagger}$          | $<2.4$        | \texttt{Tight}      | $<0.30$              | $<0.45$        | $<2.0$        | $>0.4$                     |
|---------------------------+---------------+---------------------+----------------------+---------------+---------------------+----------------------+----------------+---------------+----------------------------|
| 3\textsuperscript{rd} $e$ | $<2.5$        | \texttt{Medium}     | $<0.3$               | --            | --                  | --                   | $<0.45$        | $<2.0$        | --                         |
| 3\textsuperscript{rd} $\mu$ | $<2.4$        | \texttt{Medium}     | $<0.3^{\dagger}$           | --            | --                  | --                   | $<0.45$        | $<2.0$        | --                         |
|---------------------------+---------------+---------------------+----------------------+---------------+---------------------+----------------------+----------------+---------------+----------------------------|

We remind the reader that the phase-space is always divided into three regions, according to the triggers being used, as described in [[#sec:trigger_regions]].

* B Quark Pair
:PROPERTIES:
:CUSTOM_ID: sec:b_pair_sel
:END:

We now turn to the \hbb{} process, where jets coming from a Higgs boson must be selected, following at least one of the below criteria:
+ Two AK4 jets with $\pt > 20\,\si{\GeV}$ and $|\eta| < 2.5$ for 2017 and 2018, with a $\Delta \text{R} > 0.5$ distance between each jet and each selected $\tau$ candidate.
  For 2016 the $|\eta| < 2.4$ is instead used.
+ One AK8 boosted jet, with the distance between the jet and both selected $\tau$ candidates of $\Delta \text{R} > 0.8$.

Additionally, the \hbb{} selection is improved by applying a discrimination algorithm to identify b jets, dubbed \hhbtag{}.
The algorithm is based on studies done in the context of \newcite{cms_hh_bbtt}.
At its core, a \ac{DNN} architecture assigns a score between 0 and 1 to all possible AK4 b jet candidates, and the two jets with the highest score are selected.
The score stands for on how confident the model is that a particular b jet originated from a \hbb{} decay.
The architecture of the model is characterized by the following elements:
+ Five concatenated \ac{LSTM} layers [[cite:&lstm]], using a sigmoid activation function. After each layer, a batch normalization step is applied.
+ Ten \ac{TDD} layers [[cite:&keras]], with sigmoid as activation function. A batch normalization step is also applied between each layer.
+ Binary cross-entropy as the loss function [[cite:&cross_entropy]], minimized with the =AdamW= algorithm [[cite:&adamw]].
+ A final \ac{TDD} layer with only one unit and with a sigmoid as activation function, providing the final score.

\noindent The algorithm has been retrained with \ac{UL} data, using both nonresonant and resonant \ac{ggF} \bbtt{} signal samples, in order to provide the best performance possible.
The algorithm is trained via cross-validation with two folds, a procedure described in [[#sec:pdnn]].
A total of 14 input features are considered, including the score of =DeepJet=, several kinematic variables, \ac{MET}.
Categorical variables are also used, such as the data-taking year and decay channel.
The performance of the algorithm is evaluated and compared to the previous version, and also to other b jet \ac{ID} algorithms, as shown in [[fig:hhbtag_comp]].
The retrained version provides better results than all alternatives, across the full probed $\mx$ range.
The so-called /purity/ is used as comparison metric:
#+NAME: eq:purity
\begin{equation}
    \text{purity}^{\text{classifier}} = \frac{\text{N}^{\text{classifier}}_{\text{true}}}{\text{N}^{\text{classifier}}} \: ,
\end{equation}
\noindent where $\text{N}^{\text{classifier}}_{\text{true}}$ is the number of events in which the selection of the b jet pair candidate matched the ground truth's definition, and $\text{N}^{\text{classifier}}$ represents the total number of events where a candidate is reconstructed.
The matching uses a $\Delta\text{R}<0.5$ cut around the direction of the reconstructed b jet.

#+NAME: fig:hhbtag_comp
#+CAPTION: Comparison of the purity for the \spin{0} \bbtt{} resonant signal, as a function of $\mx$, between the original (=v1=) and retrained (=v2=) \hhbtag{} versions, and two other \ac{CMS} algorithms, namely \ac{PNet} and =DeepJet= (also known as =DeepFlavour=). Purity is defined in [[eq:purity]]. The retrained algorithm clearly provides the best performance across the entire mass range.
#+BEGIN_figure
\centering
#+ATTR_LATEX: :width .9\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/purity_ggF_spin0_2018.pdf]]
#+END_figure

For AK8 jets, the \hhbtag{} algorithm is not employed; the \ac{PNet} discriminant [[cite:&particle_net]] is used instead, as explained in [[#sec:categorization]].

* Categorization
:PROPERTIES:
:CUSTOM_ID: sec:categorization
:END:    
With the selection fully defined, we proceed to split selected events in orthogonal categories.
The categories are meant to boost the analysis' sensitivity.
That happens because, during the extraction of the final results, each category is separately fitted.
In the limit where all categories have identical event topologies, the result of the fit should be equal to a fit performed on the selected events taken together.
If the categories possess some distinguishing features, as is the case in our analysis, a per-category fit improves the result, since individual background sources can be better constrained.

The categorization scheme follows the angular radius parameters adopted in the reconstruction of jets within \ac{CMS}.
+ $\Delta \text{R}(\text{b},\text{b})\,> \,0.8$: each b-quark is reconstructed as a AK4 jet;
+ $0.4 \, < \, \Delta \text{R}(\text{b},\text{b})\,< \,0.8$: the two b-quarks are reconstructed both as two AK4 jets and as one large AK8 jet;
+ $\Delta \text{R}(\text{b},\text{b})\,< \,0.4$: the two b-quarks are reconstructed as an AK8 jet only.
\noindent The so-called /resolved/ topologies refer to the first scenario, while /boosted/ topologies refer to the other two.
In this analysis two resolved categories and one boosted category are defined, as follows:
+ Events with a reconstructed AK8 jet having $m_{\text{SoftDrop}} > 30\,\si{\GeV}$, $\pt > 250\,\si{\GeV}$, $\Delta \text{R}(\text{jet},\tau)\,> \,0.8$ for both \taus{}, and a \ac{PNet} discriminant score passing the \ac{LP} \ac{WP} are assigned to the \boostcat{} category.
  The score was introduced in [[eq:pnet]].
+ Events with two AK4 jets and no AK8 jets, where only one of its b jet candidates passes the =Medium= \ac{WP} of =DeepJet,= are assigned to the \rescat{1} category.
+ Events with two AK4 jets and no AK8 jets, where both its b jet candidates pass the =Medium= \ac{WP} of =DeepJet=, are assigned to the \rescat{2} category.
\noindent The \rescat{2} category provides the most sensitive measurements for resonance masses below \SI{\sim 700}{\GeV}, while the \boostcat{} category drives the analysis sensitivity for resonance masses above \SI{\sim 700}{\GeV}.

The categories are attributed following a specific order of precedence, as illustrated in [[fig:cat_flowchart]], where \rescat{} has precedence over the other categories.
Other possibilities were tried, namely giving the top precedence to the \boostcat{} category, but the choice used here provided the best final results.

#+NAME: fig:cat_flowchart
#+CAPTION: Flowchart of the analysis categorization. Three categories are defined: \rescat{1}, \rescat{2} and \boostcat{}, based on the number of AK4 and AK8 jets, and on the =Loose= \ac{WP} of the \ac{PNet} discriminant.
#+BEGIN_figure
\centering
\begin{tikzpicture}[scale=1.4, every node/.style={scale=1.4}]
    % Place nodes
    \node [block1] at (3.5,8) (top)   {Number of AK4 b jets};
    \node [class] at (1.7,6.05) (res2b) {\textbf{res2b}};
    \node [block1] at (4.5,6) (ak8)   {Is an AK8 jet present?};
    \node [block2] at (2,4) (pnet)  {Passes the PNet Loose WP?};
    \node [block1] at (5,4) (ak4)   {Number of AK4 b jets};
    \node [class] at (1,2) (boost) {\textbf{boosted}};
    \node [disc]  at (3.5,2) (disc)  {discard};
    \node [class] at (6,2) (res1b) {\textbf{res1b}};
    
    % Draw edges
    \draw [-{Latex[length=2mm]}] (top) -- (res2b) node[midway, left]  {$\geq 2$};
    \draw [-{Latex[length=2mm]}] (top) -- (ak8)   node[midway, right] {$< 2$};
    \draw [-{Latex[length=2mm]}] (ak8) -- (pnet)  node[midway, left] {yes};
    \draw [-{Latex[length=2mm]}] (ak8) -- (ak4)   node[midway, right] {no};
    \draw [-{Latex[length=2mm]}] (pnet) -- (boost)   node[midway, left] {yes};
    \draw [-{Latex[length=2mm]}] (pnet) -- (disc)   node[midway, right] {no};
    \draw [-{Latex[length=2mm]}] (ak4) -- (disc)   node[midway, left] {0};
    \draw [-{Latex[length=2mm]}] (ak4) -- (res1b)   node[midway, right] {1};
    
\end{tikzpicture}
#+END_figure

* Invariant Mass Cut
:PROPERTIES:
:CUSTOM_ID: sec:mass_cut
:END:
Events classified as resolved are required to have reconstructed visible masses of the b and $\tau$ pairs within a rectangular window.
The goal is to maximize signal acceptance, requiring at least 98% of signal presence.
These cuts remove the tails of the mass spectrum, and potential outliers, easing the task of discriminators further down in the analysis chain.
The mass cut also allows to define \acp{CR} with low signal contamination, useful to assess the proper modeling of some of the main analysis' backgrounds.

In order to define the mass window interval, the \ac{ggF} \spin{0} and \spin{2} signal samples are utilized.
The samples are merged, considering all mass and spin configurations at once. 
The \eletau{}, \mutau{} and \tautau{} channels have been separately considered to estimate the rectangular cuts.
The event selection, in addition to the \basecat{} requirements, includes the following conditions:
+ presence of two resolved b jet candidates passing the =Loose= b-tag \ac{WP};
+ b jets matched to a generated b quark.
\noindent The maximum and minimum values of the $\mbb$ and $\mtautau$ visible masses are calculated from their 99.5% and 0.5% quantiles.
To define the mass window interval, the limits for $\mbb$ are calculated first. 
An additional requirement is then added while computing the limits for $\mtautau$: to consider $\mbb$ only within the limits calculated in the previous step.
The values obtained are:
+ visible $\mtautau$ between \SI{20}{\GeV} and \SI{130}{\GeV};
+ $\mbb$ between \SI{40}{\GeV} and \SI{270}{\GeV}.
\noindent The cuts ensure a very high signal efficiency.
It has been shown that tighter cuts, although providing a larger S/B ratio, result in a poorer limit when compared to a \ac{DNN} discriminant [[cite:&higgs_bbtautau_nonres]].
The boundaries of the cut are thus kept very loose, focusing on acceptance and not purity.
The two-dimensional distribution of $\mbb$ versus $\mtautau$ is displayed in [[fig:windowMassRegions]], where a red rectangle highlights the computed mass interval.
We note that the visible mass signal distributions are similar for all mass points, including the ones not displayed.

#+NAME: fig:windowMassRegions
#+CAPTION: Illustration of the rectangular window mass cut (in red) on top of signal (\SI{700}{\GeV} and \SI{1}{\TeV} for, respectively, the top and middle rows) and background (bottom row). The three analysis channels are represented in the left, middle and right columns.
#+BEGIN_figure
#+ATTR_LATEX: :width .325\textwidth :center :options trim={2cm 2cm 2cm 2cm},clip
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-700-GeV_etau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center :options trim={2cm 2cm 2cm 2cm},clip
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-700-GeV_mutau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center :options trim={2cm 2cm 2cm 2cm},clip
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-700-GeV_tautau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center :options trim={2cm 2cm 2cm 2cm},clip
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-1000-GeV_etau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center :options trim={2cm 2cm 2cm 2cm},clip
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-1000-GeV_mutau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center :options trim={2cm 2cm 2cm 2cm},clip
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-1000-GeV_tautau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center :options trim={2cm 2cm 2cm 2cm},clip
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_TT-DY_etau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center :options trim={2cm 2cm 2cm 2cm},clip
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_TT-DY_mutau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center :options trim={2cm 2cm 2cm 2cm},clip
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_TT-DY_tautau_baseline_2018.pdf]]
#+END_figure

* Control Regions
:PROPERTIES:
:CUSTOM_ID: sec:control_regions
:END:

It is often useful to understand if single background sources are being correctly modeled.
Additionally, one often wants to perform cross-checks on data outside the \ac{SR}, to avoid creating biases, but with a similar topology.
An example would be to determine correction weights using a data-driven approach.
\Acp{CR} are thus introduced, one centered on $\ttbar$ and another designed to be \ac{DY}-dominated:
+ $\pmb{\ttbar}$ *CR*:
  Events satisfy the \basecat{} selection, and must be associated to the \eletau{} or \mutau{} channels.
  They additionally do not include any AK8 jets, thus having a resolved topology.
  The two AK4 jets must pass the =Medium= =DeepJet= \ac{WP}, just like events in the \rescat{2} category.
  This requirements increases the fraction of $\ttbar$ events, compared to other backgrounds associated with lighter jets.
  Finally, the mass of the $\tau\tau$ system must lie above \SI{130}{\GeV}, in order for the \ac{CR} to be orthogonal to the rectangular mass cut introduced in [[#sec:mass_cut]].
+ *DY CR*:
  Events satisfy the \basecat{} selection, and must be associated to the \mumu{} channel.
  They additionally do not include any AK8 jets, thus having a resolved topology.
  Either one or two AK4 jets must pass the =Medium= =DeepJet= \ac{WP}, mimicking the \rescat{1} or \rescat{2} categories, depending on the use case.
  The fraction of \ac{DY} events decreases with \rescat{2} cuts, as $\ttbar$ increases.
  Finally, an invariant mass cut is requested around the mass of the Z boson, to remove any non-\ac{DY} background source.
  Notice that there is no need to ensure orthogonality with respect to the rectangular mass cut, since the \mumu{} channel is not added to the final analysis fit.

In the \xhhbbtt{} analysis, \acp{CR} regions are used to inspect the agreement of data and \ac{MC} in different kinematic and categorical distributions.
In particular, they are quite useful to determine whether additional corrections are required for specific background sources.


