:PROPERTIES:
:CUSTOM_ID: sec:analysis1_intro
:END:

The study of topologies involving a pair of Higgs bosons is immediately associated to the precise determination of the shape of the Higgs potential, and the consequences such a measurement can bring to the field of \ac{HEP}.
There is however another way of framing these processes, namely by hypothesizing the existence of \ac{BSM} particles, massive enough to decay into a Higgs boson pair: \xhh{}.
The exploration of such topologies is primarily driven by the profusion of well-motivated theoretical models predicting the existence of resonances coupled to the Higgs sector.
Examples of the aforementioned models are certain \ac{SUSY} flavors, \acp{WED}, and models where one or more singlets or doublets are added, much in the vein the successful ideas introduced by the Higgs Mechanism.
The observation of a new resonant state would immediately revolutionize Particle Physics, representing the first definitive evidence of \ac{BSM} physics at a collider experiment.

#+NAME: fig:tau_decay_modes
#+CAPTION: Illustration of the nine combinations two tau leptons can decay into (left), with corresponding leptonic and hadronic Feynman diagrams (right). Six decays are considered in the \xhhbbtt{} analysis, highlighted in orange and corresponding to 88% of the total \ac{BR}. The gray box shows the decays that were not considered in the limits, due to very large backgrounds, which make them much less sensitive than the remaining channels. The \mumu{} channel is however used to derive trigger \acp{SF} and to define a background control region. All decay channels include at least one neutrino, and thus \ac{MET}.
#+BEGIN_figure
\centering
#+ATTR_LATEX: :width 1.\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/TauDMs.pdf]]
#+END_figure

The specific choice of the \bbtt{} decay channel can be well justified.
It has consistently been observed to be one of the most sensitive HH channels, due to a balance between background contamination and \ac{BR} size.
Its decay topology is experimentally rather complex, consisting on two tau leptons and two jets initiated by a b quark.
The tau leptons are themselves unstable, with a \SI{2.9E-13}{\second} mean lifetime [[cite:&PDG]].
They decay via leptonic or hadronic channels.
Leptonic decays include either an electron or a muon, plus neutrinos in the form of \ac{MET}.
Hadronic decays are more complex, featuring various combinations of neutral and charged hadrons.
When considering the \htt{} process, there are are thus nine possible decay combinations, as illustrated in [[fig:tau_decay_modes]].
In our analysis, we take into account the channels where at least one hadronically-decaying $\tau$ candidate \tauh{} is present: \eletau{}, \mutau{} and \tautau{}.
These three dominate, given their total \ac{BR} of 88%.
An additional channel, \mumu{}, despite not being used to extract the final results given it small \ac{BR} of 3%, is utilized as a \ac{CR} for \ac{DY} and $\ttbar$ backgrounds, and is used to compute \ac{MET} trigger \acp{SF}, as described in [[#sec:met_trigger_sfs]].
The \eleele{} and \elemu{} channels are not exploited due to their small combined \ac{BR} of 9%, and because they are expected to be overwhelmed by \ac{DY} (only for \eleele{}) and $\ttbar$ backgrounds.
Concerning the second Higgs boson candidate, the b-jets must be discriminated against other types of particles, mostly lighter jets, using techniques discussed in [[#sec:physics_objects]].
All the above hints at the complexities of the \bbtt{} channel, which encompasses most topologies a collider experiment can be exposed to.
The event display of a \hhbbtt{} candidate is shown in [[fig:event_display_res2b_2016]], recorded by \ac{CMS} on July 5\textsuperscript{th} 2016.

#+NAME: fig:event_display_res2b_2016
#+CAPTION: \ac{CMS} event display of a \hhbbtt{} candidate, in 2016. Two views are shown, namely $R$ vs $z$ (top) and 3D Cartesian coordinates (top). Red and blue represent, respectively, \ac{ECAL} and \ac{HCAL} energy deposits, where the magnitude is proxied by the dimension of each bar. Tracks are represented in green. The four dark green jet cones highlight the two b jets and two hadronic \taus{}. The event passed the \rescat{2} selection. The selection of the analysis categories is defined in [[ref:sec:categorization]].
#+BEGIN_figure
\centering
#+ATTR_LATEX: :width .9\textwidth :center
[[~/org/PhD/Thesis/figures/intro/EvDisp_2016_tauTau_res2b_RhoZ.pdf]]
#+ATTR_LATEX: :width .9\textwidth :center
[[~/org/PhD/Thesis/figures/intro/EvDisp_2016_tauTau_res2b_3D.pdf]]
#+END_figure

Finally, our analysis is also strongly motivated by a recent result of the \ac{ATLAS} Collaboration on the \xhhbbtt{} process [[cite:&atlas_bbtt_res]].
There, a small excess is observed at $\mx\sim 1\,\si{\TeV}$, with a local (global) significance of \SI{3.1}{\sigma} (\SI{2.0}{\sigma})[fn:: Local and global significances are explained in [[#sec:cls]]].
The analysis presented in this work thus aims to replicate the excess with the \ac{CMS} experiment, or instead demonstrate it to be a statistical fluctuation.
It is thus fundamental to obtain a sensitivity at least as good as the one from the \ac{ATLAS} result, especially close to the $\mx$ region where the tension was observed.

The analysis strategy represents an enormous improvement over the latest iteration of the resonant \xhhbbtt{} analysis performed at \ac{CMS}, which used 2016 data only [[cite:&cms_hh_bbtt]].
Besides the almost four-fold increase in luminosity, the analysis strategy has been completely revamped, and not many similarities remain.
The current strategy was instead initially based on the recent \ac{CMS} nonresonant \bbtt{} publication [[cite:&higgs_bbtautau_nonres]].
However, a series of important upgrades has since been implemented, as summarized in [[tab:improvements]].
It is worth remarking that the resonant and nonresonant studies mutually benefit from each other.
Just like the work here presented took advantage from decisions made in the past, upgrades in the analysis here presented are already being used for \run{3} \bbtt{} analyses to be published in the future.
Our analysis exploits \ac{pp} collision data recorded at a $\sqrt{s}=13\,\si{\TeV}$ center-of-mass energy by the \ac{CMS} experiment during \run{2}, for a total of \SI{138}{\invfb}.

#+NAME: tab:improvements
#+CAPTION: List of improvements adopted in the resonant \xhhbbtt{} analysis with respect to the previous \ac{CMS} \bbtt{} analyses. The updates cover all stages of the workflow illustrated in [[fig:analysis_flow]]. All improvements are explained in detail in this or in [[#sec:analysis2_intro]]. 
#+ATTR_LATEX: :placement [!h] :center t :align ll :environment mytablewiderrows
|--------------+----------------------------------------------------------------------------------|
| *Stage*        | *Improvement*                                                                      |
|--------------+----------------------------------------------------------------------------------|
| Samples      | Updated to \ac{UL} datasets                                                      |
|              | Consider NLO \ac{DY} samples (scaled to NNLO) instead of \ac{LO}                 |
|              | Added \ac{MET} datasets                                                          |
| Selection    | Various updates, notably a phase-space increase at low \ac{pt} and high \ac{eta} |
|              | Optimization of the boosted category                                             |
|              | Retraining of the \hhbtag{} algorithm                                            |
|              | New $\mtautau$ regression algorithm                                              |
| Discriminant | New parameterized \ac{DNN} algorithm                                             |
| Statistics   | Additional systematic uncertainties                                              |
|--------------+----------------------------------------------------------------------------------|

# disclaimer
It should be clear that the work reported in this Chapter and in [[#sec:analysis2_intro]] does not correspond to the efforts of a single person, but rather the collective work of an (international) analysis team.
I can however claim to have been one the main analyzers, with contributions on multiple fronts.
I was deeply involved in the definition and implementation of the new trigger strategy, including the computation of \ac{MET} triggers \acp{SF}, the definition of trigger regions, the removal of event overlaps, and the improvement of older implementations of the legacy triggers.
I have updated some of the analysis selections, either due to updates brought by the \ac{UL} datasets, or in order to extend the available phase-space.
The introduction or upgrade of multiple corrections was also done as a part of my Thesis: new $\tau$ identification \acp{SF}, electron, tau and jet energy corrections and resolutions, including their propagation to the definition of \ac{MET}, and others.
This was strongly related to the computation of systematic uncertainties, where I was also played a major role.
I also ported an estimation technique for $\ttbar$ background \acp{SF}, developed for the \bbtt{} nonresonant analysis, which is however currently believed not to be required.
More generally, I was involved in virtually all steps of the rewrite and optimization of the analysis software, in the documentation and review process of the work, and on the production of results, in the form of binned distributions and final limits.

#+NAME: fig:analysis_flow
#+CAPTION: Illustration of the analysis workflow. Each stage is covered in detail in later Sections of this Chapter. The strategy can be visualized in different stages, starting with the selection of the \run{2} data and \ac{MC} samples to consider. A series of triggers is then applied, in order to select events which might have a \bbtt{} topology. A series of selection cuts is then applied, constructing individual objects, and then pairs. Three categories are defined to enhance the analysis sensitivity. This information, together with a large number of \ac{MC} \acp{SF}, is used as input to our \ac{DNN} discriminant, which assigns a probability for an event to be signal or background. Such a variables is exploited in a binned maximum likelihood fit to extract 95% \acp{CL}, where systematic uncertainties are includes as nuisances.
#+BEGIN_figure
\centering
#+ATTR_LATEX: :width 1.\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/AnalysisFlow.pdf]]
#+END_figure

# summary
In this Chapter we set the stage for the signal extraction and statistical analysis done in [[#sec:analysis2_intro]].
We describe the data and \ac{MC} samples, triggers, physics objects and selection in [[ref:sec:samples,sec:triggers,sec:physics_objects,sec:selection]], respectively.
We then detail a new algorithm which performs the regression of the invariant mass of the $\tau\tau$ pair in [[#sec:tautau_regression]].
We conclude this first Chapter dedicated to the \xhhbbtt{} analysis by covering the way how backgrounds are modeled and corrected, in [[ref:sec:backgrounds,sec:mc_corrections]].
The full analysis workflow is illustrated in [[fig:analysis_flow]].
