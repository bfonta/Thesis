:PROPERTIES:
:CUSTOM_ID: sec:selection
:END:

The observation of \xhhbbtt{} naturally requires the capability to precisely reconstruct the two pairs of b-jets and tau leptons.
Having introduced all single physics objects included in the \bbtt{} topology, we can now describe in detail the full event selection, which aims at providing the subset of events processed that match the signal of interest.
However, the selection should not be too strict, or equivalently lead to a very high \bbtt{} purity; that could hinder analysis steps to come, and specifically affect the final discriminator, by reducing its training data size.
Given the rarity of HH processes, it is imperative to measure as many \hhbbtt{} events as possible; the goal of the selection is to maximize signal acceptance.

The selection starts from the data passing the analysis triggers, and is performed in various stages, as also highlighted in [[fig:analysis_flow]].
The stages proceed in order, by targeting single objects first, such as b-jets, leptons and \tauhs{}, and later pairs of such quantities, as defined by the decays of the two Higgs bosons.
Once the two H candidates have been found, an additional two-dimensional invariant mass cut is applied on the $\mbb$ and $\mtautau$ plane, to further restrict the phase-space of interest, removing potential outliers, and to provide validation \acp{CR}.
A categorization step immediately follows, where /categories/ are defined.
This step separates events according to the topology of the b-quark pair, creating two resolved and one boosted category.
The categories are created in order to boost the sensitivity of a dedicated /discriminant variable/, which is described in the next Chapter.

In the following, we detail the selection cuts applied to leptons and b-jets in [[ref:sec:tau_pair_sel,sec:b_pair_sel]], and mention the invariant mass cut in [[#sec:mass_cut]].
We then proceed by describing the categorization in [[#sec:categorization]].
Finally, we provide the definitions of the two \acp{CR} used in the analysis, which are used to train the discriminant and are visualized in [[#sec:control_regions]].

* Tau Lepton Pair
:PROPERTIES:
:CUSTOM_ID: sec:tau_pair_sel
:END:

This step aims at identifying the visible decay products of one of the \SI{125}{\GeV} Higgs bosons decaying to a $\tau$ pair.
Selected signal events are required to have at least one $\tau$ candidate decaying hadronically and that has been reconstructed by the \ac{HPS} algorithm.  
The =DeepTau= discriminator [[cite:&deeptau]] identifies \tauhs{}, distinguishing them from jets, electrons and muons.
Due to charge conservation, \ac{HPS} decay modes with two prongs are explicitly rejected.
Furthermore, all events assigned the $\text{h}^{\pm}\pi^{0}\pi^{0}\nu_{\tau}$ topology are analyzed as though they were $\text{h}^{\pm}\pi^{0}\nu_{\tau}$.
This happens because the former is much rarer than the latter, and the \ac{HPS} algorithm is not tuned to reconstruct decays containing two $\pi^0\text{s}$.
This same assignment is also taken into account when applying =DeepTau= \acp{SF}, as described in [[#sec:deep_tau_sfs]]
The identification requirement applied to \tauhs{} is the =Medium= \ac{WP} of the =DeepTauVSjet= algorithm, the =Tight= =DeepTauVSmu= \ac{WP}, and the =VVLoose= =DeepTauVSe= discriminator.
Their efficiencies are listed in [[tab:deeptau_wps]].
The choice of \acp{WP} is related to the \acp{WP} used by the Tau \ac{POG} to derive \acp{SF} for genuine \tauhs{}, which have a dependency on =DeepTauVSmu= and =DeepTauVSe=.
The reasoning is to use corrections as close to POG recommendations as possible, in order to reach a good data/MC agreement in all relevant parts of the parameter space.

#+NAME: tab:max_min_cuts
#+CAPTION: List of the minimum $\pt$ and maximum $|\eta|$ thresholds considered for electron, muon and tau lepton candidates. These value are a consequence of hard limits imposed by object-specific \acp{SF},as provided by the relevant \acp{POG}. Leptons firing triggers with tighter \ac{pt} cuts must apply the thresholds according to [[eq:ptTreshold]].
#+ATTR_LATEX: :placement [!h] :center t :align lcc :environment mytablewiderrows
|------------+--------------------------+-------------|
| *Object*     | $\pmb{\pt\,[\si{\GeV}]}$ | $\pmb{\vert\eta\vert}$ |
|------------+--------------------------+-------------|
| Electron   |                       10 |         2.5 |
| Muon       |                       15 |         2.4 |
| Tau lepton |                       20 |         2.3 |
|------------+--------------------------+-------------|

All events lying above the minimum $\pt$ or below the maximum $|\eta|$ values reported in [[tab:max_min_cuts]] are considered.
The values come from hard limits imposed by the isolation and \ac{ID} trigger \acp{SF} used in the analysis.
Importantly, the limits are not driven by \ac{HLT} cuts, since such a choice would defeat the purpose of the $\metnomu$ trigger.
We look for lepton candidates passing simple kinematical, isolation and \ac{ID} criteria, as described in [[tab:chn_sel]].
After all lepton candidates have been inspected, the analysis channels are defined according to specific priority rules.
An event is classified as \mutau{} if a single muon candidate passes all criteria.
If two muons pass the criteria, the event becomes \mumu{}
In case no muon is selected, we check whether any electron was selected.
In a similar way, in case a single electron candidate is present, the event is associated the \eletau{} channel.
If two electrons are present, the event would be assigned the \eleele{} channel, but it is instead discarded, as we are not taking this channel into consideration.
If neither muons or electrons are found, the event is classified as \tautau{}, as long as a two \tauhs{} are present.
Within each pair, leptons are ordered as follows, depending on the channel:
+ $\pmb{\tau_{e}\tau_{\text{h}}}$ *and* $\pmb{\tau_{\mu}\tau_{\text{h}}}$: \mutau{} and \eletau{}: the first position is assigned to the leptonic leg, either a muon or an electron.
+ $\pmb{\tau_{\text{h}}\tau_{\text{h}}}$:
  The pairs are first sorted according to the =DeepTau= score of the first lepton.
  If the two first legs have the same isolation, the highest \ac{pt} of first leg is used to order the pair.
  If the \ac{pt} is also identical, \ie{} the pairs share the same first leg, the pair with the most isolated second leg is preferred.
  If ambiguity is still present, priority is given to the pair with the highest \ac{pt} of the second leg.

\noindent This channel classification strategy was chosen because it maximizes event purity while removing event overlaps among the three different final states.
Finally, as described in [[#sec:third_lepton_sel]], a third lepton veto is applied to all events.
Any event where an electron or muon is present, on top of the 2 leptons used to build the \ditau{} pair, is discarded.

#+NAME: tab:chn_sel
#+CAPTION: Selections defining the analysis channels. Besides the ones noted in the table, opposite charges are requested between the two leptons, and the \ac{pt} thresholds follow [[eq:ptTreshold]], except when the the leptons fired only \ac{MET}, in which case no specific cuts are requested, and [[tab:max_min_cuts]] is followed. The $|\eta|$ cut on the second lepton in \eletau{} and \mutau{} can be 2.1 if the event only fires the cross trigger. With the exception of not applying a $\Delta_{xy}$ cut on \tauhs{}, the $\Delta_{xy}$ and $\Delta_{z}$ cuts below are equal for the two pair objects, are are provided in \si{\mm}.
#+ATTR_LATEX: :placement [!h] :center t :align lccccccccc :environment mytablewiderrows
|-----------+---------------+---------------------+----------------------+---------------+---------------------+----------------------+----------------+---------------+----------------------------|
| *Chn.*      | $\pmb{\vert\eta_1\vert}$ | $\pmb{\text{ID}_1}$ | $\pmb{\text{Iso}_1}$ | $\pmb{\vert\eta_2\vert}$ | $\pmb{\text{ID}_2}$ | $\pmb{\text{Iso}_2}$ | $\pmb{\Delta_{xy}}$ | $\pmb{\Delta_{z}}$ | $\pmb{\Delta\text{R}(\ell_1,\ell_2)}$ |
|-----------+---------------+---------------------+----------------------+---------------+---------------------+----------------------+----------------+---------------+----------------------------|
| \eletau{} |           2.5 | \texttt{Tight}      |                  0.1 |           2.3 | \texttt{DeepTau}    | \texttt{DeepTau}     |           0.45 |           2.0 |                        0.4 |
| \mutau{}  |           2.4 | \texttt{Tight}      |                 0.15 |           2.3 | \texttt{DeepTau}    | \texttt{DeepTau}     |           0.45 |           2.0 |                        0.4 |
| \tautau{} |           2.3 | \texttt{DeepTau}    |     \texttt{DeepTau} |           2.3 | \texttt{DeepTau}    | \texttt{DeepTau}     |             -- |           2.0 |                        0.4 |
| \mumu{}   |           2.4 | \texttt{Tight}      |                 0.15 |           2.4 | \texttt{Tight}      | 0.30                 |           0.45 |           2.0 |                        0.4 |
|-----------+---------------+---------------------+----------------------+---------------+---------------------+----------------------+----------------+---------------+----------------------------|

+ add table caption to main text as well
  
A subsequent check that the event is firing the trigger path associated to the selected final states and that the selected offline leptons are geometrically matched to the online ones is performed.
With respect to the 2016 data analysis, the use of cross-triggers allows for a much lower threshold on the $\pt$ of the $\tau$ leptons, hence the request of a fixed cut on the lepton $\pt$ is dropped from the \ditau{} pair selection.
Instead, each reconstructed offline lepton is required to pass a \ac{pt} threshold depending on the \ac{HLT} trigger path fired by the event:
#+NAME: eq:ptTreshold
\begin{equation}
  \pt^{\text{offline}} \, \geq \, \pt^{\text{HLT}}\ + \, \text{threshold}\:,
\end{equation}

\noindent where $\pt^{\text{offline}}$ is the transverse momentum of the offline selected lepton, $\pt^{\text{HLT}}$ is the \ac{pt} threshold applied at trigger level and ``threshold'' is a variable depending on the lepton type: \SI{1}{\GeV} for electron trigger legs, \SI{2}{\GeV} for muon trigger legs, \SI{5}{\GeV} for the \ditau{} trigger, and \SI{10}{\GeV} for the \stau{} trigger.
The thresholds are chosen to be conservative with respect to the trigger turn-on curves.
For events passing a given kind of trigger (\sele{}, \smu{}, \celetau{}, \cmutau{}, \stau{}, \ditau{}, $\metnomu$), the \ac{pt} selection is determined by the loosest threshold on the object at trigger level among those available for that kind of trigger, with the exception of the \ac{MET} trigger.
When the \ac{MET} trigger fires, no explicit \ac{pt} or \ac{eta} cuts are applied to the objects, as described in [[#sec:trigger_regions]].

We remind the reader that the phase-space is always divided into three regions, according to the triggers being used.
For a visualization of the kinematic trigger region cuts, refer once more to the middle column of [[fig:kinTriggerRegions]].
Events are required to pass any of the triggers described in [[#sec:triggers]] and the offline leptons are required to match the \ac{HLT} ones.
In addition, the following is required:

** Third lepton veto
:PROPERTIES:
:CUSTOM_ID: sec:third_lepton_sel
:END:

Some events can include multiple leptons, and their choice becomes a matter of some ambiguity.
I mentioned above \mutau{} events take precedence over \eletau{} events, and therefore at the decay channel level no ambiguity is present.
However, nothing forbids an event to include, on top of a hadronic tau, two muons, or two electrons, as long as they satisfy the requirements in [[tab:chn_sel]].
For those cases, there would be multiple ways to choose the "correct" lepton, \ie{} the lepton truly coming from the relevant Higgs boson decay.
To simplify the selection and avoid taking the wrong decision, events with a third lepton are rejected.
Additionally, the following conditions must be true for the event to be rejected:
+ An electron of $|\eta_{e}| < 2.5$ and $p_T > 10\,\si{\GeV}$. The electron passes the \logicand{} between the =Medium= \ac{MVA} non-iso-identification criteria and the relative isolation requirement $\mathcal{I}_{\text{rel}}^{e} < 0.3$. The reconstructed electron production vertex must be close to the main primary vertex within a distance $\Delta_{xy} < 0.045\,\si{\cm}$ and $\Delta_{z} < 0.2\,\si{\cm}$;
+ A muon of $|\eta_{\mu}| < 2.4$ and $p_T > 10\,\si{\GeV}$ and passing the =Medium= particle--flow muon and \texttt{HighPt} track muon identification criteria, plus the relative particle--flow and track isolation requirements, $\mathcal{I}_{\text{rel}}^{\text{track-}\mu} < 0.3$ and $\mathcal{I}_{\text{rel}}^{\text{PF-}\mu} < 0.3$, respectively. The reconstructed muon production vertex must be close to the main primary vertex within a distance $\Delta_{xy} < 0.045\,\si{\cm}$ and $\Delta_{z} < 0.2\,\si{\cm}$.
This veto also helps removing background events with two leptons and a fake \tauh{}, as for instance diboson processes, or fully leptonic decays of $\ttbar{}$.

* B Quark Pair
:PROPERTIES:
:CUSTOM_ID: sec:b_pair_sel
:END:

This step of the analysis is aimed at selecting jets from the decay of the second \SI{125}{\GeV} Higgs boson in a $\bbbar$ pair.
For events to be selected, one of the following must occur:
+ two jets with $\pt > 20\,\si{\GeV}$ and $|\eta| < 2.5$ ($|\eta| < 2.4$) for 2017 and 2018 (2016), with a $\Delta \text{R} > 0.5$ distance between each jet and both selected $\tau$ candidates;
+ one boosted jet, with the distance between the jet and both selected $\tau$ candidates of $\Delta \text{R} > 0.8$.

On top, and based on studies done for Ref. [[cite:&cms_hh_bbtt]], the $H \rightarrow bb$ selection was improved by developing a new algorithm to identify b-jets, dubbed \hhbtag{}.
This algorithm is based on a neural network architecture and it is described in [[#sec:hh_btag]].
For each event belonging to one of the resolved categories, all possible b-jet candidates are assigned a score by the \hhbtag{} algorithm.
The two jets with the highest score are taken to be the two b-jets originating from the decay of the Higgs boson.
In the boosted category the \hhbtag{} algorithm is not employed; the \ac{PNet} discriminant [[cite:&particle_net]] is used instead, as explained in [[#sec:sig_extraction]].

** HH b-tagging network
:PROPERTIES:
:CUSTOM_ID: sec:hh_btag
:END:

The introduction of deep learning techniques on the identification of jet, b-jet and hadronic tau decays has already been demonstrated to be well suited for improving the discovery significance within \ac{CMS}. 
This section describes the \hhbtag{} algorithm, meant to improve the selection of b-jets in \hhbbtt{} events in CMS, and introduced in the nonresonant analysis [[cite:&higgs_bbtautau_nonres]].
The same algorithm has been retrained with \ac{UL} data, using both nonresonant and resonant \bbtt{} samples, in order to provide the best performance possible.
The performance of the algorithm is evaluated and compared with respect to the previous version and to the b-0jet identification algorithms already used in our analysis to the select the \hbb{} Higgs boson candidate: =DeepTau= and \ac{PNet}.

@continues in the AN HH_Btag.tex@

** Signal extraction
:PROPERTIES:
:CUSTOM_ID: sec:sig_extraction
:END:

Events are split in three orthogonal categories: *res1b*, *res2b* and *boosted*.
This categorization scheme arises naturally from the reconstruction of jets within the \ac{CMS} framework.
The latter is based on the radial separation between the the two b-quarks:
+ $\Delta \text{R}(\text{b},\text{b})\,> \,0.8$: each b--quark is reconstructed as a jet applying the AK4 algorithm (resolved jet);
+ $0.4 \, < \, \Delta \text{R}(\text{b},\text{b})\,< \,0.8$: the two b--quarks are reconstructed both as two separated AK4 jets and as a large--radius jet (fatjet) using the AK8 algorithm;
+ $\Delta \text{R}(\text{b},\text{b})\,< \,0.4$: the two b--quarks are reconstructed only as an AK8 jet.
The resolved categories target the first scenario ($\Delta \text{R} \, (\text{b},\text{b})\,> \,0.4$) while the boosted category targets the other two scenarios.
Events with a reconstructed fatjet having $m_{\text{SoftDrop}} > 30\,\si{\GeV}$, $\pt > 250\,\si{\GeV}$, $\Delta \text{R}(\text{jet},\tau)\,> \,0.8$ for both \taus{} and \ac{PNet} discriminant passing the \ac{LP} \ac{WP} fall in the \textbf{boosted} category.
Events without an AK8 jet are assigned to the resolved categories.
They are further categorised based on the AK4 jet =DeepJet= score:
+ Resolved 2jet--1tag, *res1b*:
Events in this category are such that only one of the two b-jet candidates passes the =Medium= \ac{WP} for all the final states.
+ Resolved 2jet--2tag, *res2b*:
Events in this category are such that both b-jet candidates pass the =Medium= \ac{WP} for all the final states.
The *res2b* category provides the most sensitive measurements for resonance masses below \SI{700}{\GeV} while the *boosted* category drives the analysis sensitivity for resonance masses above \SI{700}{\GeV}.

Events classified as resolved are required to have reconstructed visibile masses of the b and $\tau$ pairs within a rectangular window.
In order to define the mass window interval, gluon-fusion \spin{0} and \spin{2} signal samples are utilized.
The samples cover a range of masses spanning from \SI{250}{\GeV} to \SI{3}{\TeV}, and involve the production of resonance particles that subsequently decay into pairs of Higgs bosons and $\tau$ leptons.
The samples were merged, considering all mass and spin configurations at once. 
The three \mutau{}, \eletau{} and \tautau{} analysis channels have been considered to estimate the rectangular cuts.
The event selection, in addition to the baseline requirements, includes the following conditions:

+ presence of two resolved b-jet candidates for the \hbb{} candidate reconstruction, passing the loose bTag working point;
+ b-jet hadron flavour equals 5, corresponding to the PDG code of the $b$ quark;
+ $\tau$ leptons with opposite charge.

\noindent The maximum and minimum values of the $\mbb$ and $\mtt$ visible masses are calculated from their 99.5% and 0.5% quantiles, and are estimated to be:

+ $\mtt$ visible mass between \SI{20}{\GeV} and \SI{130}{\GeV};
+ $\mbb$ between \SI{40}{\GeV} and \SI{270}{\GeV}.

\noindent The cuts ensures a very high signal efficiency.
To define the mass window interval, the limits for $\mbb$ are calculated first. 
An additional requirement is then added while computing the limits for $\mtt$: to consider $\mbb$ only within the limits calculated in the previous step.
The two-dimensional distribution of $\mbb$ versus $\mtt$ is displayed in [[fig:windowMassRegions]], where a red rectangle highlights the computed mass interval.
We note that the visible mass signal distributions are similar for all mass points.

#+NAME: fig:windowMassRegions
#+CAPTION: Illustration of the rectangular window mass cut (in red) on top of signal (\SI{700}{\GeV} and \SI{1}{\TeV} for, respectively, the top and middle rows) and background (bottom row). The three analysis channels are represented in the left, middle and right columns.
#+BEGIN_figure
#+ATTR_LATEX: :width .325\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-700-GeV_etau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-700-GeV_mutau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-700-GeV_tautau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-1000-GeV_etau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-1000-GeV_mutau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_Radion-1000-GeV_tautau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_TT-DY_etau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_TT-DY_mutau_baseline_2018.pdf]]
#+ATTR_LATEX: :width .325\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/draw_mass_TT-DY_tautau_baseline_2018.pdf]]
#+END_figure

It has been shown that a more discriminant mass cut, altough providing a larger S/B ratio, results in a poorer limit when compared to the limit obtained with a \ac{DNN} discriminator [[cite:&higgs_bbtautau_nonres]].
Given that the signal events are better discriminated by the parameterised DNN put in place for this analysis,
the goal of applying the mass window is instead to remove significantly outlying background events in regions where no signal overlap is expected.

[[fig:categories_scheme]] describes schematically how events are split into different categories and the discriminating variable used for signal extraction in each category.
The final limit extraction is performed fitting the distributions of the score of a \ac{pDNN} in the three analysis categories.
The network aims at discriminating \xhhbbtt{} signal events from background, and is described [[fig:categories_scheme]].

#+NAME: fig:categories_scheme
#+CAPTION: Descriptive scheme of the event categorization.
#+BEGIN_figure
\centering
#+ATTR_LATEX: :width .6\textwidth :center
[[~/org/PhD/Thesis/figures/analysis1/AnalysisFlowDiagram.pdf]]
#+END_figure

** Resolved jets
** Boosted jets

* Invariant Mass Cut
:PROPERTIES:
:CUSTOM_ID: sec:mass_cut
:END:

* Categorization
:PROPERTIES:
:CUSTOM_ID: sec:categorization
:END:

@ define "baseline selection" somewhere @

These cuts remove the tails of the mass spectrum, and outliers in these regimes, easing the task of discriminators further down in the analysis chain.
It also allow to define control regions with low signal contamination, useful to assess the proper modelling of some of the main analysis' backgrounds.

In the extraction of the final results, each category is fitted separately.
Differences in categories can help constrain the likelihood fit.

* Control Regions
:PROPERTIES:
:CUSTOM_ID: sec:control_regions
:END:
As we can see in @insert figure reference@ for the \ac{DY} \ac{CR}, the data/MC agreement improves significantly when requiring a strong b-tag identification \ac{WP}.
This is due to bad modelization of the light jets coming with the \ac{DY} simulation, which has also been observed in the nonresonant \bbtt{} analysis [[cite:&higgs_bbtautau_nonres]].
Ultimately, the categories which matter are the ones being fitted, here the one where the ~DeepJet~ requirement is applied.
