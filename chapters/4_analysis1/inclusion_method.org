:PROPERTIES:
:CUSTOM_ID: sec:inclusion_method
:END:

For completeness, we provide a brief description of a general method for estimating \acp{SF} when considering the \logicor{} of any number of triggers.
The implementation and testing of the method represented a significant part of my PhD, but ended up not being fully exploited by reasons detailed below.
We nevertheless describe the underlying idea, as it can serve as basis for future work.

The probability P that at least one out of $\text{N}_{\text{items}}$ trigger items $i$ accepts an event $j$ with trigger item bit $x$ is given by [[cite:&inclusion_method]]:
#+NAME: eq:prob_or
\begin{equation}
  \text{P}_{j} = 1 - \prod^{\text{N}_{\text{items}}}_{i} \left[ 1 - x_{ij}\epsilon_{i}(q_{j})\right]
\end{equation}
\noindent where $\epsilon$ refers to the trigger efficiency, depending on variables $q$, defined as the number of events passing trigger item $i$ and some reference trigger, divided by the number of events passing the same reference trigger.
In [[eq:prob_or]] we use the fact that the triggers we consider are not prescaled and different data runs have the same conditions.
Correlations might exist between triggers, so we rewrite $x_{1j}\epsilon_{1j}x_{2j}\epsilon_{2j} \rightarrow x_{1j}\epsilon_{1j}x_{2j}\epsilon_{2|1j}$, and similar for higher order terms with $\text{N}_{\text{items}}>2$, where $\epsilon_{i}(q_{j}) \equiv \epsilon_{ij}$ simplifies the notation, and the symbol "$|$" stands for a condition probability.
Note the commutativity relationship $\epsilon_{1j}\epsilon_{2|1j} = \epsilon_{2j}\epsilon_{1|2j}$.
Using Bayes' theorem, we express the efficiency product as an \textit{intersection efficiency} $\epsilon_{1\cap2j}$, representing the fraction of events passing triggers 1 and 2, plus some reference trigger, when compared to all events passing the same reference trigger.
The probability becomes:
#+NAME: eq:example3
\begin{align}
  \text{P}_{j} &= x_{1j}\epsilon_{1j} + x_{2j}\epsilon_{2j} + x_{3j}\epsilon_{3j} + \cdots \nonumber \\
               &- x_{1j}x_{2j}\epsilon_{1\cap2j} - x_{1j}x_{3j}\epsilon_{1\cap3j} - x_{2j}x_{3j}\epsilon_{2\cap3j} - \cdots \nonumber \\
               &+ x_{1j}x_{2j}x_{3j}\epsilon_{1\cap2\cap3j} + \cdots
\end{align}
\noindent For each intersection, we must define the variables $q$.
We should consider the ones used in the definition of trigger items, since efficiencies will mostly depend on the variables defining their corresponding \ac{HLT} trigger paths.
For instance, $q=\pt(\mu)$ is a reasonable choice for the \smu{} trigger.
Finally, we can correct our \ac{MC} distributions event-by-event, using \acp{SF} defined as follows:
#+NAME: eq:inclusion_sf
\begin{equation}
  \text{Event}_{\text{MC, Corrected}} =   \text{Event}_{\text{MC}} \times \frac{\text{P}_{\text{Data}}}{\text{P}_{\text{MC}}}
\end{equation}
\noindent This is called the \textit{inclusion method}, and its implementation is challenging. 
Many intersections might have to be considered.
Their calculation is done as a function of different variables $q$ (potentially 1D, 2D or 3D $\epsilon$ distributions), for all intersections.
We nevertheless note that the terms in [[eq:prob_or]] with more triggers will naturally be the ones which contain less events overall, and can be dropped when statistics lie below a tunable threshold.
Importantly, orthogonal reference triggers have to be found for each intersection, where the latter should have enough statistics.
Finally, the inclusion method represents a new approach, thus requiring extensive validation.

The method also brings important advantages.
Contrary to common division-like methods, all data are used.
It may become very advantageous when significant overlaps exist between triggers. 
Indeed, most analysis do not consider the \logicor{} between triggers due to the increased complexity.
I developed an analysis-independent framework to measure all intersection efficiencies.
A preliminary test was carried using the \mutau{} channel, exploiting its large statistics.
For simplicity, we used the muon \ac{pt} as $q$ across all intersections.
We consider the \logicor{} between the \stau{} and \mutau{} triggers, and apply the standard analysis selection.
We observe that the \acp{SF} calculated via [[eq:prob_or]] provide better Data/MC agreement in the analysis phase-space than the \acp{SF} provided centrally by \ac{CMS}.
The improvement is observed only for the variable being used, namely the lepton \ac{pt}.
This encouraging result can be explained, as our custom \acp{SF} are calculated with kinematics specific to \xhhbbtt{}, while central \acp{SF} must be general enough to be used by multiple analyses.
For this test, variables not correlated with the \ac{pt} are not affected.

The inclusion method is not applied to the \xhhbbtt{} analysis, despite being fully implemented and despite a preliminary validation.
This can be explained by the fact that the complete validation would require more time, which would not be then dedicated to work on the analysis as a whole.
There were also significant challenges in defining appropriate reference triggers and datasets for each intersection combination.
Furthermore, the correct definition of possibly multi-dimensional bins for each variable $q$, together with the integration of custom \acp{SF} with \acp{SF} centrally provided by \ac{CMS}, was no simple task.
Additionally, the project was experimental, and there was no guarantee the final result would converge into robust and usable corrections.
For all the reasons above, we decided to create a trigger strategy with non-overlapping regions, as described in [[#sec:trigger_regions]], so that the \logicor{} between all triggers would not have to be considered.
However, the developed framework was not left unused.
Firstly, given its flexibility, it was utilised with one single trigger, namely the \ac{MET} trigger studies presented in [[#sec:met_trigger_sfs]].
Secondly, it is now serving as the basis for a similar endeavour, which will hopefully be used for \run{3} \bbtt{} work.
Estimates have shown an expected acceptance gain of the order of \SI{\sim 10}{\percent} when using the full \logicor{} for the \run{3} nonresonant \hhbbtt{} analysis, compared to the trigger strategy employed in this work.
Exploiting the \logicor{} of multiple trigger is thus one of many possible approaches to increase the performance of future HH searches.
