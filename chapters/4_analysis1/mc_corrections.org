:PROPERTIES:
:CUSTOM_ID: sec:mc_corrections
:END:

* Pileup reweighting
During the \ac{LHC} \run{2} there were an average of 27, 38 and 37 \ac{pp} interactions per bunch crossing, for 2016, 2017 and 2018, respectively, as one can see in [[fig:lhc_lumi_results1]].
A deterministic annealing algorithm [[cite:&annealing_algo]] is used in order to fit the \ac{PV}, obtain the total number of vertices and define an assignment of clustered tracks to different collisions, effectively identifying all interaction vertices.
In a first step, tracks passing certain quality criteria are clustered mostly based on the their $z$ coordinate of closest approach to the beamline.
The algorithm does not directly minimize the $\chi^{2}$ of the $z$ positions of vertices and tracks, but tries instead to find the most likely distribution of track-vertex assignments for a specific value of $\chi^{2}$, and then minimizes that distribution while keeping the system in a state of maximal probability.
When compared to statistical mechanics, the annealing procedure is fully equivalent to gradual cooling, hence its name.
In the second step, the clustered tracks are fitted three-dimensionally using the entirety of the available track information.
The vertices are sorted according to the sum of $\pt^{2}$ of their associated tracks, and the vertex with the highest value is selected as the \ac{PV}.
The other vertices in the event are assumed to have been originated from \ac{PU} collisions.

The distribution of the number of interaction vertices in the \ac{MC} events do not exactly matches the one in data.
To achieve a better match between data and simulations, a standard reweighting procedure as centrally recommended by the \ac{CMS} Collaboration for \run{2} is applied to \ac{MC} events.
The provided \ac{PU} weights use a nominal \ac{MB}, inelastic \ac{pp} cross-section equal to \SI{69.2}{\milli\barn}, which is used as an input to produce the pileup histogram used for the reweighting.
The cross section includes a 4.6% uncertainty, which must be taken into account when computing systematic uncertainties.
This is discussed in [[#sec:syst_pu]].

* Pileup jet identification
* Jet energy smearing
* Legacy trigger scale factors
* Single tau trigger scale factors
* MET trigger scale factors
:PROPERTIES:
:CUSTOM_ID: sec:met_trigger_sfs
:END:

** MET trigger inefficiency in 2017
We can see that in 2017 the trigger does not becomes fully efficient for high $\metnomu$ values.
This is because the ~HLT_PFMETNoMu120_PFMHTNoMu120_IDTight~ trigger was not active in the last runs of 2017.
To recover the missing luminosity, we decided to consider instead, for 2017 only, the \logicor{} between ~HLT_PFMETNoMu120_PFMHTNoMu120_IDTight~ and ~H2LT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT6F~.
We can see in ref:fig:lumi_vs_runnumber_2017 that the new trigger collects more data during the last few runs in 2017.
Indeed, looking at the recomputed efficiency and SF plot in ref:fig:eff_mumu_2017, considering the two triggers taken together, we can observe a full recovery of the lost efficiency.

#+NAME: fig:lumi_vs_runnumber_2017
#+CAPTION: Recorded luminosity as a function of the run number, for the 2017 data-taking period. The two $\metnomu$ triggers considered for the analysis in 2017 are shown. While the one with the $\httt$ cut (empty red circles) was not active in the first runs,  it collected all available luminosity once it was on. This enables to recover some luminosity lost by the trigger shown in blue crosses, as one can see by looking at the last few runs, where a discrepancy exists. We consider the \logicor{} of the two triggers in the analysis.
#+BEGIN_figure
#+ATTR_LATEX: :width 1.\textwidth :center
[[~/org/PhD/Thesis/figures/mc_corrections/met_scalefactors/lumi_vs_runnumber_2017.pdf]]
#+END_figure

#+NAME: fig:eff_mumu_2017
#+CAPTION: $\metnomu$ data and MC trigger efficiencies (top panels) and corresponding \acp{SF} (lower panels), for 2017. The left (right) plot was obtained in the \mumu (\mutau{}) channel as described in the text. The \mumu{} channel is used for validation, while \mumu is used to extract the analysis \acp{SF}. \acp{SF} are extracted from the ratio of the data and MC sigmoid fits, implemented to smoothen the \ac{SF}'s distribution. They are taken to be one for $\metnomu$ values above \SI{350}{\GeV}.
#+BEGIN_figure
#+ATTR_LATEX: :width .5\textwidth :center
[[~/org/PhD/Thesis/figures/mc_corrections/met_scalefactors/eff_17_mumu_MET.pdf]]
#+ATTR_LATEX: :width .5\textwidth :center
[[~/org/PhD/Thesis/figures/mc_corrections/met_scalefactors/eff_17_mutau_MET.pdf]]
#+END_figure

* B-tag reshaping
:PROPERTIES:
:CUSTOM_ID: sec:btag_reshape
:END:

To account for discrepancies in the b-tag performance in MC, the whole b-tagging discriminant distribution in MC is corrected
to match the one in data, following the shape calibration procedure recommended by the b-Tag and Vertexing POG.
%
For each MC event with a given jet configuration, the event weight $\omega$ is computed as:
\[
\omega = \prod_i^{N_{jets}} SF\left(D_i,  p_{Ti}, \eta_i \right)
\]
where the scale factors SF are provided by the BTV POG as a function of the discriminator score,
transverse momentum and pseudo-rapidity of the jets.
%
The event weights computed with this method should change only the shape of the b-tagging discriminant.
Before applying any b-tag selection criteria, expected event yields should be preserved: this means that the number of events
(i.e. the sum of event weights) before and after applying b-tag weights should be identical.
In order to ensure this, the sum of event weights before and after applying b-tag event weights, without requiring any b-tag selection,
is computed. The ratio $r = \sum \omega_{\text{before}} / \sum \omega_{\text{after}}$ represents a phase-space extrapolation
and is multiplied to the b-tag event weight. The values of these $r$ factors are reported in [[tab:btag_rfactor]].

#+NAME: tab:btag_rfactor
#+CAPTION: Values of the $r$ factors used to correct the b-tag event weights and preserve the normalization of the MC samples.
\begin{table}[htbp]
    \centering
    \setlength{\tabcolsep}{10pt}
    \begin{tabular}{lll}
	\hline \\[-1em]
	Year & Final state & $r$ factor \\ \hline \\[-1em]
	\multirow{3}{*}{2016} & \mutau{}  & 1.0081 \\
			      & \eletau{} & 1.0068 \\
			      & \tautau{} & 1.0103 \\[+0.3em] \hline \\[-1em]
	\multirow{3}{*}{2017} & \mutau{}  & 0.9993 \\
			      & \eletau{} & 0.9949 \\
			      & \tautau{} & 0.9547 \\[+0.3em] \hline \\[-1em]
	\multirow{3}{*}{2018} & \mutau{}  & 1.0039 \\
			      & \eletau{} & 1.0040 \\
			      & \tautau{} & 0.9795 \\[+0.3em] \hline \\[-1em]
    \end{tabular}
\end{table}

* Particle Net SFs
:PROPERTIES:
:CUSTOM_ID: sec:pnet_sfs
:END:

* DeepTau scale factors for hadronic $\tau$'s
:PROPERTIES:
:CUSTOM_ID: sec:deep_tau_sfs
:END:

* Lepton scale factors
